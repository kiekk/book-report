## 2장 느려진 서비스, 어디부터 봐야 할까

### 처리량과 응답 시간
- 앱을 실행했을 때 로딩 중인 이미지가 오래 표시되거나 통신사 사이트에서 요금 정보를 조회하는 데 10초 이상 걸린다면 흔히 성능이 나쁘다고 말한다.
- 성능이 저하되면 가장 눈에 띄는 현상은 결과가 늦게 표시되는 것이다.
- 너무 오래 걸려서 타임아웃(시간 초과)에러가 발생하기도 한다.
- 사용자는 무언가를 실행할 때 동작하기까지 걸린 시간으로 성능을 판단하지만 실제로는 다양한 지표가 성능과 관련되어 있다.
- 네트워크 속도, 디스크 속도, 메모리 크기, 디바이스(스마트폰)의 CPU 속도 등이 여기에 해당한다.
- 이런 다양한 지표 중에서 서버 성능과 관련 있는 중요한 지표를 2가지 꼽자면 응답 시간과 처리량을 들 수 있다.


### 응답 시간
- 응답 시간은 사용자의 요청을 처리하는 데 걸리는 시간을 의미한다.

클라이언트(앱이나 브라우저 같은)가 서버로 요청을 보내는 과정은 크게 2단계로 이루어진다.
1. 서버에 연결: TCP를 이용해서 서버에 연결한다.
2. 데이터 전송: 정해진 규칙(프로토콜)에 따라 데이터를 서버에 전송한다. 예를 들어, HTTP 프로토콜에 따라 POST 방식으로 JSON 데이터를 보낼 수 있다.

응답 시간은 2가지로 나누어 측정하기도 한다.
1. TTFB(Time To First Byte): 응답 데이터 중 첫 번째 바이트가 도착할 때까지 걸린 시간
2. TTLB(Time To Last Byte): 응답 데이터 중 마지막 바이트가 도착할 때까지 걸린 시간

`응답 데이터의 크기가 작다면 TTFB와 TTLB는 거의 동일하지만 파일 다운로드처럼 전송할 데이터가 크거나 네트워크 속도가 느리면 TTFB와 TTLB는 차이가 커질 수 있다.`


- 응답 시간은 API 요청 전송 시간, 서버의 처리 시간, API 응답 전송 시간으로 나뉜다.
- 서버 개발자는 주로 서버의 처리 시간을 확이하는데 서버의 처리 시간은 다음과 같은 요소를 포함한다.
  - 로직 수행 (if, for...)
  - DB 연동 (SQL 실행)
  - 외부 API 연동
  - 응답 데이터 생성(전송)

- 이 중 DB 연동과 외부 API 연동이 큰 비중을 차지한다.



### 처리량
- 처리량은 단위 시간당 시스템이 처리하는 작업량을 의미하는데 흔히 TPS나 RPS로 처리량을 나타낸다.
  - TPS(Transaction Per Second): 초당 처리하는 트랜잭션 수
  - RPS(Request Per Second): 초당 처리하는 요청 수

- 최대 TPS는 시스템이 처리할 수 있는 최대 요청 수를 의미한다.
- 서버가 한 번에 5개의 요청을 처리할 수 있다고 한다면 (요청당 처리 시간은 1초로 가정)
- 최대 TPS는 5가 되며 동시에 들어오는 요청 수가 5를 초과하면 서버는 초과한 요청을 나중에 처리한다.


- 응답 시간의 증가는 사용자 이탈로 이어질 수 있기 때문에 이를 방지하기 위해 2가지 방법을 고려할 수 있다.
  - 서버가 동시에 처리할 수 있는 요청 수를 늘려 대기 시간 줄이기: 서버의 스펙 확장으로 TPS 증가
  - 처리 시간 자체를 줄여 대기 시간 줄이기: 요청당 처리 시간을 감소하여 TPS 증가

    
#### TPS 확인
- 스카우터, 핀포인트, 뉴렐릭 같은 모니터링 시스템을 활용하여 TPS를 확인할 수 있다.



### 서버 성능 개선 기초
- 성능 문제는 서비스 초기에는 잘 발생하지 않고 사용자가 늘면서 점차 나타난다.
- 트래픽이 늘고 데이터가 쌓이면서 간헐적으로 응답 시간이 느려지는 현상이 발생한다.
- 이 때 나타나는 전형적인 증상은 다음과 같다.
  - 순간적으로 모든 사용자 요청에 대한 응답이 심각하게 느려진다. 10초 이상 걸리는 요청이 늘어나고 다수의 요청에서 연결 시간 초과와 같은 오류가 발생한다.
  - 서버를 재시작하면 잠시 괜찮다가 다시 응답 시간이 느려지는 현상이 반복된다.
  - 트래픽이 줄어들 때까지 심각한 상황이 계속된다.


- TPS를 높이기 위해서는 먼저 성능 문제가 발생하는 지점을 찾아야 하는데 이 때 모니터링 도구가 유용하다.
- 적절한 모니터링 도구가 없다면 로그라도 남겨야 한다.
- 의심되는 코드의 실행 시간을 로그로 남겨두면 나중에 성능 문제가 다시 발생했을 때 개선할 부분을 찾는 데 도움이 된다.


### 수직 확장과 수평 확장
- 성능 문제를 일으키는 원인을 찾았다면 빠르게 적용할 수 있는 개선안을 도출해야 한다.
- 빠르게 적용할 수 있는 방법은 수직 확장(scale-up)을 하는 것이다.

### 수직 확장
- 수직 확장은 CPU, 메모리, 디스크 등의 자원을 증가시키는 것을 말하낟.
- 하지만 트래픽이 지속해서 증가하면 언젠가는 결국 또다시 성능 문제가 발생하는데, 그 때마다 수직 확장을 반복할 수는 없다.
- 수직 확장은 비용이 많이 든다. (또한 높은 스펙의 하드웨어는 가격이 상당하다.)


### 수평 확장
- 수직 확장은 한계가 있기 때문에 동일한 스펙의 서버를 추가로 투입해 TPS를 높이는 수평 확장(scale-out)을 고려해야 한다.
- 하지만 TPS를 높이기 위해 무턱대고 서버를 추가해서는 안 된다.
  - DB에서 성능 문제가 발생한다고 해서 서버를 추가하면 오히려 DB에 가해지는 부하가 더 커지고 성능 문제는 더 악화된다.
  - 외부 API의 성능이 문제인 경우에도 서버를 추가한다고 해서 TPS가 향상되지 않는다.
- 따라서 실제 병목 지점이 어디인지 파악한 후에 적용하는 것이 좋다.
- 추가로 수평 확장의 경우 서버의 개수가 늘어나기 때문에 이에 대한 부하 분산도 고려해야 한다.
  - ex: 로드 밸런서를 이용한 부하 분산


### DB 커넥션 풀
- 네트워크에서 DB를 연결하고 종료하는 시간은 전체 응답 시간에 영향을 준다.
- 매 요청마다 DB를 연결하고 종료하면 트래픽이 증가할 때 급격하게 처리량이 떨어지기도 한다.
- 이런 문제를 피하기 위해 DB 커넥션 풀을 사용한다.
- DB 커넥션 풀은 DB 연결을 미리 만들어두고 요청이 들어오면 미리 만들어둔 연결을 재사용하는 방식이다.

- Spring Boot에서는 HikariCP를 기본 커넥션 풀로 사용한다.

### 커넥션 풀 크기
- 커넥션 풀 크기는 커넥션 풀에 미리 생성해둘 커넥션 개수를 말한다.
- 커넥션 풀 크기보다 많은 요청이 들어오면 커넥션 풀에서 커넥션을 얻지 못하고 대기하게 된다.
- 커넥션 풀에서 커넥션을 얻기 위해 대기하는 시간을 줄이려면 전체 응답 시간과 TPS를 고려하여 커넥션 풀 크기를 지정해야 한다.
- 커넥션 풀 크기를 늘리면 처리량을 높일 수 있다.
- 하지만 그렇다고 무턱대고 늘리면 안된다.
  - DB 서버의 CPU 사용률이 80%에 육박하는 상황에서 커넥션 풀 크기를 늘리면 DB에 가해지는 부하가 더 커져 쿼리 실행 시간이 급격히 증가할 수 있다.
- 따라서 DB 상태를 보고 늘려야 한다.


### 커넥션 대기 시간
- 커넥션 풀에 사용할 수 있는 커넥션이 없을 떄 커넥션을 얻기 위해 기다릴 수 있는 최대 시간을 의미한다.
- 지정된 대기 시간 안에 커넥션을 구하지 못하면 DB 연결 실패 에러가 발생한다.
- 커넥션을 얻기 위해 대기하는 시간만큼 응답 시간도 길어진다.
- 대기 시간을 짧게 설정하면 에러가 발생하기는 하지만, 서버 부하를 일정 수준으로 유지할 수 있으며 서버를 안정적으로 운영하는 데 도움이 된다.


### 최대 유휴 시간, 유효성 검사, 최대 유지 시간
- 최대 유휴 시간은 사용되지 않는 컬렉션을 풀에 유지할 수 있는 최대 시간을 의미한다.
- 유효성 검사는 커넥션이 정상적으로 사용할 수 있는 상태인지 여부를 확인하는 절차이다.
  - 일부 커넥션 풀은 유효성 검사를 위해 실제 쿼리를 실행하기도 한다.
  - `SELECT 1 FROM dual`, `SELECT 1` 같은 쿼리를 실행하여 커넥션이 정상적으로 동작하는지 확인한다.
- 최대 유지 시간은 커넥션이 생성된 시점부터 풀에 유지될 수 있는 최대 시간을 의미한다.


### 서버 캐시
- DB 서버를 확장하려면 비용이 많이 든다.
- DB 서버를 확장하지 않고도 응답 시간과 처리량을 개선하고 싶다면 캐시 사용을 고려할 수 있다.


### 적중률과 삭제 규칙
- 캐시가 얼마나 효율적으로 사용되는지 적중률(hit rate)로 판단할 수 있다.
```markdown
적중률 (hit rate) = 캐시에 존재한 건수 / 캐시에서 조회를 시도한 건수

ex: 캐시에서 데이터를 100번 조회했을 때 87번은 해당 데이터가 존재했다고 할 경우 적중률은 0.87, 즉 87%가 된다.
```

- 적중률을 높이는 가장 간단한 방법은 캐시에 최대한 많은 데이터를 저장하는 것인데, 이 방법에는 무리가 있다. 
- 캐시는 메모리 자원을 사용하기 때문에 무작정 캐시에 모든 데이터를 저장할 수는 없다.
- 따라서 캐시에 데이터가 가득 찰 경우 새로운 데이터를 저장하기 위해 기존 데이터를 삭제해야 한다.
- 삭제할 데이터를 선택하는 규칙을 캐시 삭제 규칙이라고 하며 아래와 같은 규칙이 있다.
  - LRU(Least Recently Used): 가장 오랫동안 사용되지 않은 데이터를 삭제한다.
  - LFU(Least Frequently Used): 가장 적게 사용된 데이터를 삭제한다.
  - FIFO(First In First Out): 가장 먼저 들어온 데이터를 삭제한다.

- 많은 서비스에서는 오래된 데이터보다 최신 데이터를 더 자주 조회하는 경향이 있다.
- 즉, 오래된 데이터는 캐시에 있어도 사용되지 않을 가능성이 높다.


### 로컬 캐시와 리모트 캐시
- 서버가 사용하는 캐시에는 크게 두 종류가 있다.
  - 로컬 캐시(인 메모리 캐시): 서버 프로세스와 동일한 메모리를 캐시 저장소로 사용한다.
  - 리모트 캐시: 별도 프로세스를 캐시 저장소로 사용한다.

#### 로컬 캐시
- 장점
  - 서버 프로세스와 캐시가 동일한 메모리 공간을 사용하므로 캐시 데이터에 빠르게 접근할 수 있다.
  - 별도의 외부 연동이 필요하지 않아 구조를 단순하게 유지할 수 있다는 장점도 있다.
- 단점
  - 캐시에 저장할 수 있는 데이터 크기에 제한이 있다.
  - 서버 프로세스를 시작하면 메모리에 존재하던 캐시 데이터가 모두 삭제되어 일시적으로 캐시 효율(적중률)이 순간적으로 떨어진다.


#### 리모트 캐시
- 장점
  - 캐시를 유연하게 확장할 수 있다.
  - 대표적인 리모트 캐시 기술인 레디스는 여러 대의 레디스 서버를 이용해서 수평 확장할 수 있는 기능을 제공한다. (redis cluster)
  - 서버 프로세스가 재시작되더라도 레디스에 저장된 캐시 데이터는 그대로 유지된다.
- 단점
  - 서버 프로세스는 캐시 프로세스와 데이터를 주고받기 위해 네트워크 통신을 해야 한다.
    - 메모리에 저장된 데이터에 직접 접근하는 것과 비교하면 네트워크 통신은 상대적으로 느리다.
  - 리모트 캐시를 운영하려면 별도의 서버 장비와 프로세스가 필요하기 때문에 시스템 구조가 복잡해진다.


### 캐시 사전 적재
- 트래픽이 순간적으로 급증하는 패턴을 보인다면 캐시에 데이터를 미리 저장하는 것도 고려할 필요가 있다.


### 캐시 무효화
- 캐시를 사용할 때 반드시 신경 써야 할 점은 유효하지 않은 데이터를 적절한 시점에 캐시에서 삭제하는 것이다.
- 원본이 변경됐는데 캐시에 저장된 데이터가 갱신되지 않으면 사용자는 오래된 잘못된 정보를 확인하게 되는 문제가 발생할 수 있다.


### 가비지 컬렉터와 메모리 사용
- 메모리를 많이 사용하고 생성된 객체가 많을수록 사용하지 않는 객체를 찾는 데 시간이 오래 걸린다.
- 대량으로 객체가 생성되는 것을 방지하려면 조회 범위를 제한해야 한다.
- 마찬가지로 한 번에 조회할 수 있는 데이터의 개수도 트래픽 규모와 메모리 크기에 맞춰 제한해야 한다.


- 파일 다운로드와 같은 기능을 구현할 때는 스트림을 활용한다.
```java
byte[] bytes = Files.readAllBytes(Paths.of("path")); // 파일을 한 번에 메모리에 로딩
out.write(bytes);

/*
    이 코드는 30MB 크기의 파일을 100명이 동시에 다운로드하면 약 3GB의 메모리가 필요하게 된다.
 */
```

```java
InputStream is = Files.newInputStream(Path.of("path"));
byte[] buffer = new byte[8192]; // 8KB 메모리
int read;
while ((read = is.read(buffer, 0, 8192)) >= 0) {
    out.write(buffer, 0, read);
}
// is.transferTo(out)와 동일 코드

/*
    이 코드는 파일을 한 번에 읽지 않고 8KB씩 읽어서 처리한다.
    동시에 100명이 다운로드를 요청하더라도 필요한 메모리는 약 800KB로 줄어든다.
 */
```


### 응답 데이터 압축
- 응답 시간에는 데이터 전송 시간이 포함되는데 이 전송 시간은 2가지 요인에 영향을 받는다.
  - 네트워크 속도
  - 전송 데이터 크기


- 웹 서버가 전송하는 응답 데이터 중에서 HTML, CSS, JS, JSON과 같이 텍스트로 구성된 응답은 압축하면 데이터 전송량을 크게 줄일 수 있다.
- 실제로 텍스트 데이터를 gzip으로 압축하면 70% 이상 크기를 줄일 수 있으며 데이터 전송 크기가 줄어든 만큼 전송 시간도 빨라진다.
- 응답 데이터를 압축해 데이터 전송량을 줄이는 것은 응답 시간뿐만 아니라 비용에도 영향을 준다.
  - 클라우드 환경에서는 트래픽 자체가 비용으로 직결되기 때문이다.
- 아파치, Nginx와 같은 웹 서버는 압축 기능을 제공하고 있으므로 약간의 설정만 추가하면 즉시 효과를 볼 수 있다.

```markdown
Accept-Encoding: gzip, deflate

웹 브라우저나 HTTP 클라이언트는 Accept-Encoding 헤더를 통해 서버에 처리할 수 있는 압축 알고리즘을 알린다.
웹 서버는 Accept-Encoding 헤더에 명시된 알고리즘 중에서 자신이 지원하는 방식이 있을 경우 해당 압축 알고리즘으로 응답 데이터를 압축해서 전송한다.
이 때 사용된 압축 알고리즘은 Content-Encoding 헤더에 명시된다.
```

- HTML, CSS, JS, JSON과 같은 텍스트 형식의 응답은 압축률이 높아 효과적이다.
  - 반면 jpeg 이미지나 zip 파일처럼 이미 압축한 데이터에는 다시 압축해도 효과가 없다.
- 웹 서버에서 압축을 적용했더라도 방화벽이 이를 해제해 응답할 수 있다.


### 정적 자원과 브라우저 캐시
- 정적 자원은 전체 트래픽에서 상당한 비중을 차지한다.
- 이미지가 많은 온라인 쇼핑몰 사이트의 첫 페이지는 정적 자원이 전체 데이터의 80%를 차지하기도 한다.
- 같은 이미지나 js 파일을 매번 다운로드하면 서버 입장에서 좋을 게 없다.
- 트래픽은 비용이다.


- 클라이언트 캐시를 활용하면 서버가 전송하는 트래픽을 줄이면서 브라우저가 더 빠르게 화면을 표시할 수 있다.
  - `Cache-Control`, `Expires` 헤더를 이용해 클라이언트가 응답 데이터를 일정 시간 동안 저장해둘 수 있도록 설정할 수 있다.


### 정적 자원과 CDN
- 브라우저 캐시는 브라우저 단위로 동작하기 때문에 동시에 많은 사용자가 접속하면 순간적으로 많은 양의 이미지, JS, CSS를 전송하게 된다.
- 이런 문제를 해결하는 방법 중 하나는 CDN(Content Delivery Network)을 이용하는 것이다.
  - 대표적인 CDN 서비스로는 Amazon CloudFront, Cloudflare, Akamai 등이 있다.
- CDN은 콘텐츠를 제공하기 위한 별도의 네트워크를 의미한다.

- 사용자는 CDN이 제공하는 URL을 통해 콘텐츠에 접근한다.


### 대기 처리
- 무작정 트래픽을 처리하기 위해 서버와 DB를 증설하는 것보다 수용할 수 있는 수준의 트래픽만 받아들이고 나머지는 대기 처리하는 방법도 있다.
- 장점
  - 서버를 증설하지 않고도 서비스를 안정적으로 제공할 수 있다.
  - 사용자의 지속적인 새로 고침으로 인한 트래픽 폭증도 방지할 수 있다. 사용자는 새로 고침할 경우 순번이 뒤로 밀리기 때문에 불필요한 새로 고침을 자제하게 된다.
